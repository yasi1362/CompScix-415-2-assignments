---
title: "COMPSCIX 415.2 Homework 5/Midterm"
author: "Yasmin Makoui"
date: "7/10/2018"
output: 
  html_document: 
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load_packages, warning=FALSE, message=FALSE}
library(tidyverse)
library(mdsr)
```

My Github repository for my midterm can be found at this URL: [https://github.com/yasi1362/CompScix-415-2-assignments/tree/master/Midterm](https://github.com/yasi1362/CompScix-415-2-assignments/tree/master/Midterm)

##The tidyverse packages
###Q1 
####Can you name which package is associated with each task below?
######Plotting - ggplot2
######Data munging/wrangling - dplyr 
######Reshaping(spreading & gathering) data - tidyr
######Importing/exporting data - readr

###Q2 
####Now can you name two functions that you’ve used from each package that you listed above for these tasks?
######Plotting: 
  * geom function -> geom_point()
  * theme function -> theme_bw()
  
######Data munging/wrangling:
  * summarise()
  * filter()

######Reshaping data:
  * gather()
  * spread()

######Importing/exporting data:
  * read_csv()
  * read_delim()

##R Basics
###Q1
####Fix this code with the fewest number of changes possible so it works:
#####My_data.name___is.too00ooLong! <- c( 1 , 2 , 3 )

#####! can not be used to name a variable
  
```{r}
My_data.name___is.too00ooLong <- c( 1 , 2 , 3 )
My_data.name___is.too00ooLong
```
###Q2
####Fix this code so it works:
#####my_string <- C('has', 'an', 'error', 'in', 'it)

##### c should not be capitalized, and the closing ' was missing for "it"
  
```{r}
my_string <- c('has', 'an', 'error', 'in', 'it')
my_string
```

###Q3
####Look at the code below and comment on what happened to the values in the vector.
#####my_vector <- c(1, 2, '3', '4', 5)
#####my_vector
##### [1] "1" "2" "3" "4" "5"

#####Since number 3 and 4 were inside quotes the values changed from numbers to characters. To keep the values as numbers we should not include the quotes around numbers.
```{r}
my_vector <- c(1, 2, 3, 4, 5)
my_vector
```

##Data import/export
###Q1
####1. Download the rail_trail.txt file from Canvas (in the Midterm Exam section) and successfully import it into R. Prove that it was imported successfully by including your import code and taking a glimpse of the result.
```{r}
#import text file
file_path_rail_trail_txt <- '/Users/yasminmakoui/downloads/rail_trail.txt'
rail_trail_data <- read_delim(delim = '|', file = file_path_rail_trail_txt)

#glimpse of imported text file
glimpse(rail_trail_data)
```


###Q2
####Export the file into a comma-separated file and name it “rail_trail.csv”. Make sure you define the path correctly so that you know where it gets saved. Then reload the file. Include your export and import code and take another glimpse.
```{r}
#export csv file 
write_csv(rail_trail_data, path = '/Users/yasminmakoui/downloads/rail_trail.csv')

#import csv file
file_path_rail_trail_csv <- '/Users/yasminmakoui/downloads/rail_trail.csv'
rail_trail_data_csv <- read_csv(file = file_path_rail_trail_csv)

#glimpse csv file
glimpse(rail_trail_data_csv)
```

##Visualization
###Q1
####Critique the graphic provided in midterm: give only three examples of what is wrong with this graphic. Be concise.
  1. The size of the circles do not represent the percentages. For example for women category the circle for the 20% is much smaller than the 72%, and it could be misleading.
  2. Each category does not add up to 100%.
  3. This visual does not show the total population in the study or the numbers of each category that participated in the study. The data could be skewed depending on who participate in this study.
  
###Q2
####Reproduce this graphic using the diamonds data set.
#####See below:
```{r}
ggplot(data = diamonds) +
  geom_boxplot(mapping = aes(x = cut, y = carat, fill = color), position = "identity") + xlab("CUT OF DIAMOND") + ylab("CARAT OF DIAMOND") +
  coord_flip() 
```

###Q3
####The previous graphic is not very useful. We can make it much more useful by changing one thing about it. Make the change and plot it again.

#####The previous graph was not really clear on the colors since some where overlapping. Position "dodge" will seperate each color category.
```{r}
?geom_boxplot
ggplot(data = diamonds) +
  geom_boxplot(mapping = aes(x = cut, y = carat, fill = color ), position = "dodge") + xlab("CUT OF DIAMOND") + ylab("CARAT OF DIAMOND") +
  coord_flip() 
```

##Data munging and wrangling
###Q1
####Is this data “tidy”? If yes, leave it alone and go to the next problem. If no, make it tidy. Note: this data set is called table2 and is available in the tidyverse package. It should be ready for you to use after you’ve loaded the tidyverse package.

#####This data is not tidy since the cases and population are in the same column and the count for each are not seperated. We can tidy the table by usind a spread function to seperate cases and population counts.
```{r}
table2

spread(table2, key = type, value = count)
```

###Q2
####Create a new column in the diamonds data set called price_per_carat that shows the price of each diamond per carat (hint: divide). Only show me the code, not the output

> diamonds %>% mutate(price_per_carat = price/carat)

###Q3
####For each cut of diamond in the diamonds data set, how many diamonds, and what proportion, have a price > 10000 and a carat < 1.5? There are several ways to get to an answer, but your solution must use the data wrangling verbs from the tidyverse in order to get credit.
  * Do the results make sense? Why? Yes, based on the total population and the graph below, most of the diamonds with price abouve $10,000 are bigger that 1.5 carat.
  * Do we need to be wary of any of these numbers? Why? I think this data should be reliable. 
  
#####There are 834 diamonds over $10,000 that are smaller than 1.5 carats in the diamond data set

#####There are 53,940 observations in the diamonds data set, and the poroportaion of small diamonds to the total population is about 1.5%
  
```{r}
expensive_diamonds <- filter( diamonds, price > 10000,  carat < 1.5)
count(expensive_diamonds)
count(diamonds)

Diamonds_ratio <- (count(expensive_diamonds) / count(diamonds))

Diamonds_ratio

ggplot(data = diamonds, mapping = aes(x = carat, y = price) ) + 
         geom_point() + geom_smooth()


ggplot(data = expensive_diamonds, mapping = aes(x = carat, y = price) ) + 
         geom_point() + geom_smooth()
```

##EDA

###Q1
####During what time period is this data from? 2000 - 2015


```{r}
years <- txhousing %>% select(year) %>% group_by(year)

summarise(years)
```

###Q2
####How many cities are represented? 46 cities

```{r}
cities <- group_by(count(txhousing, city))

cities
```

###Q3
####Which city, month and year had the highest number of sales? Houston in July 2015 had the highest sales of 8945.

```{r}
subset <- txhousing %>% select(city, month, year, sales)

arrange(subset, desc(sales))
```

###Q4
####What kind of relationship do you think exists between the number of listings and the number of sales? Check your assumption and show your work. 

#####There is a positive relationship between number of sales and number of listings. The higher the number of listings in average the higher number of sales.

```{r}
ggplot(txhousing, mapping = aes(x = listings, y = sales)) +
  geom_jitter() + geom_smooth()
```


###Q5
####What proportion of sales is missing for each city?

```{r}
missing_sales <- txhousing %>% filter(is.na(sales)) 
count(missing_sales)


txhousing %>% mutate(missingsales = (is.na(sales))) %>% 
  group_by(city) %>%
  summarize(num_missingsales = sum(missingsales), 
            num_sales = sum(sales, na.rm = TRUE),
            prop_missing = num_missingsales/num_sales)
```


###Q6
####Looking at only the cities and months with greater than 500 sales:
  * Are the distributions of the median sales price (column name median), when grouped by city, different? The same? Show your work. There is no difference
  

```{r}
txhousing_sales_over <- filter(txhousing, sales > 500)

txhousing_sales_over %>% mutate(sales_over = (sales > 500)) %>%
  group_by(city, month, year, median) %>%
  summarize(total_sales = sum(sales, na.rm = TRUE), 
            new_median = median(median, na.rm = TRUE),
            difference = new_median - median)
```
  * Any cities that stand out that you’d want to investigate further? i would like to investigate more about city of Houston, since it has the highest sales across the board.

```{r}
txhousing_sales_over <- filter(txhousing, sales > 500)

txhousing_sales_over %>% mutate(sales_over = (sales > 500)) %>%
  group_by(city) %>%
  summarize(total_sales = sum(sales, na.rm = TRUE), 
            new_median = median(median, na.rm = TRUE),
            ) %>% arrange(desc(total_sales))
```

  * Why might we want to filter out all cities and months with sales less than 500? When we want to know the strongest value and derivers of sales we would want to filter out the not significant observations.
  
  
  