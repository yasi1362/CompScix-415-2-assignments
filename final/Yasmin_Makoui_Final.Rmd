---
title: "COMPSCIX 415.2 Homework 9/Final"
author: "Yasmin Makoui"
date: "8/7/2018"
output:
  html_document: 
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load_packages, warning=FALSE, message=FALSE}
library(tidyverse)
library(mdsr)
library(broom)
library(ggmap)
library(forecast)
library(tseries)
library(RgoogleMaps)
library(leaflet)
library(rgdal)
```

##Exercise 1 - Sampling Distributions, Functions and For Loops (10 points)

```{r}
# sample size
samp_size <- 100
# set the rate parameter
samp_rate <- 1/10000

# take sample
car_battery_miles <- rexp(n = samp_size, rate = samp_rate)
as.data.frame(car_battery_miles)
```

###STEP 1

####Write an R function that does the following:

####Takes a sample of size samp_size from this exponential distribution (samp_size is an input parameter for the function)
####Calculates the mean of that sample
####Calculates the standard deviation of that sample
####Returns the calculated mean and standard deviation as a list 

```{r}
samp_fun_df <- as.data.frame(samp_fun <- function(samp_size, samp_rate) {
  samp_size_samp <- car_battery_miles %>% sample_n(100) # random sample
  mod_formula <- paste0(car_battery_miles ~ 1, samp_rate)
  car_samp_lm <- lm(mod_formula, data = samp_size_samp)
  slopes <- coef(car_samp_lm)[2] # store the coefficient
  samp_avg <- mean(car_samp_lm)
  samp_std_dev <- IQR(car_samp_lm)
  stats <- as_tibble(list(samp_avg = samp_avg, samp_std_dev = samp_std_dev))
  return(stats)
})

```

###STEP 2

####Then write a loop that does this:

####Runs the above function 1000 times, with samp_size = 50 and  samp_rate = 1/10000
####Saves all of the sample means in a vector called sample_means, and all of the sample standard deviations in a vector called sample_sds

  * the following code gave me errors for tbl should be as data frame 

```
n <- 1000
slopes <- rep(NA, n) # empty vector for saving coefficients
my_mods <- my_samps <- list() # empty lists for saving models and samples
for(i in 1:n) {
  my_result <- as.data.frame(samp_fun(100, car_battery_miles))
  samp_avg[[i]] <- my_result$my_samp  
  samp_std_dev[[i]] <- my_result$my_mod
  slopes[i] <- my_result$slope # extract the slope and store in it in slopes
}
all_results <- tibble(samp_avg, samp_std_dev, slopes)
all_results
```

###STEP 3

####Then

####plot your sample means as a histogram
####Output the standard deviation of your sample means
####calculate the theoretical standard error (σ=10000, n = sample size)
####calculate the mean of the sample standard deviations and use this to calculate the empirical standard error

```
all_results %>% ggplot(aes(x = samp_avg)) +
  geom_histogram(color = 'white', fill = 'red') +
  labs(x = 'Sample Mean', title = 'Distribution of model fit on Car Battery Data') +
  theme_bw()
```

##Exercise 2 - Linear Regression (5 points)
####For this exercise we will return to the House Prices prediction dataset that we used for HW 7. You should have already downloaded the train.csv dataset before, but if you didn’t you can download it from Canvas in this week’s module.

####Load the train.csv dataset into R and fit a regression model with:
####y = SalePrice
####Features: LotArea, OverallQual, and ExterQual
####Answer these questions:
####Use the broom package to output the coefficients and the R-squared
```{r}
library(broom)
#import csv file
file_path_train <- '/Users/yasminmakoui/downloads/train.csv'
train_data <- read_csv(file = file_path_train)

# Fit a model with intercept only
mod <- lm(SalePrice ~ LotArea + OverallQual + ExterQual, data = train_data)

tidy(mod)

```

```{r}
library(broom)
# Fit a model with intercept only
mod_LA <- lm(SalePrice ~ LotArea, data = train_data)

tidy(mod_LA)
```

```{r}
library(broom)
# Fit a model with intercept only
mod_OQ <- lm(SalePrice ~ OverallQual, data = train_data)

tidy(mod_OQ)
```

```{r}
library(broom)
# Fit a model with intercept only
mod_EQ <- lm(SalePrice ~ ExterQual, data = train_data)

tidy(mod_EQ)
```

####Interpret the coefficient on LotArea: 
  * For every extra square foot in lot area, the sale price increases, on average, by $1.45, with all other features being held constant. 
```{r}
glance(mod_LA)
```

  * LotArea is statistically and practically significant.

####Interpret the coefficient on ExterQualGd
  * Excellent is our reference category for ExterQual
  * The mean difference in the sale price between Good and Excellent material on the exterior quality is -71,529 dollars, so good is less expensive by over 71K, with all other features being held constant. 

####Compare this model to the model we fit in HW 7 with GrLivArea,  OverallQual, Neighborhood. Which is the better fitting model?
```{r}
glance(mod)
```
  * Based on the adjusted R-squared (.69), the model seems to be a good fit to the data. However, the adjusted R-Squared in HW7 with GrLivArea,  OverallQual, Neighborhood is higher at (.78), which indicates the HW7 model is a better fitting model.
  
###Exercise 3 - AB Testing (5 points)
####Download the ab_test_data.csv file from Canvas. This file contains two columns: version and conversion. Each row is a visitor to a webpage. The  version column tells us which version of the webpage the visitor saw, and the  conversion column is a binary value and equals 1 if the visitor converted (0 otherwise).

####We want to perform an AB test on this data to see if the conversion rates are different for the two versions of the webpage.

####Answer these questions:

####a. What proportion of visitors converted for each version of the webpage?
```{r}
#import csv file
file_path_ab_data <- '/Users/yasminmakoui/downloads/ab_test_data.csv'
ab_data <- read_csv(file = file_path_ab_data)

ab_data_tibble <- as_tibble(ab_data)

ab_table_total <- ab_data_tibble %>% group_by(version, conversion) %>%
  summarize(conv_count = count(version))

ab_table_total
n_a <- (83+1917)
n_b <- (200+1800)

conv_a <- 83
conv_b <- 200

n_a
n_b

prop_a <- (conv_a/(n_a))
prop_b <- (conv_b/(n_b))

prop_a
prop_b
```
  * Version A coversion rate is 4.15%
  * Version B conversion rate is 10%

####b. Perform the AB test in R. What is the p-value for the AB test (hypothesis test of proportions)?
```{r}
true_a <- prop_a
true_b <- prop_b

samp_a <- rbinom(n = 1, size = n_a, prob = true_a)
samp_b <- rbinom(n = 1, size = n_b, prob = true_b)

samp_a
samp_b
```

```{r}
m <- 1000
samp_a <- rbinom(n = m, size = n_a, prob = true_a)
samp_b <- rbinom(n = m, size = n_b, prob = true_b)

plot_ab <- as_tibble(list(samp_a = samp_a/n_a, samp_b = samp_b/n_b))
plot_ab %>% ggplot(aes(x = samp_a)) +
  geom_histogram(binwidth = .001) +
  xlab('Sample proportions for Version A') +
  theme_bw()


```

```{r}
plot_ab %>% ggplot(aes(x = samp_b)) +
  geom_histogram(binwidth = .001) +
  xlab('Sample proportions for Version B') +
  theme_bw()
```

```{r}
true_a <- prop_a
true_b <- prop_b

samp_a <- rbinom(n = 1, size = n_a, prob = true_a)
samp_b <- rbinom(n = 1, size = n_b, prob = true_b)

two_prop_test <- prop.test(c(samp_a, samp_b), c(1000, 1000))
two_prop_test$p.value
```

  * The P-Value is small, so the conversion rates for Version A and B are significantly different than each other, so we'd conclude here that whatever changes were made to the webpage had an effect.

```{r}
true_a <- prop_a
true_b <- prop_b

prop_test_prop_a <- prop.test(x = samp_a, n = n_a, p = prop_a)
prop_test_a03 <- prop.test(x = samp_a, n = n_a, p = .03)
prop_test_a04 <- prop.test(x = samp_a, n = n_a, p = .04)
prop_test_a05 <- prop.test(x = samp_a, n = n_a, p = .05)
prop_test_a06 <- prop.test(x = samp_a, n = n_a, p = .06)

prop_test_prop_a$p.value
prop_test_a03$p.value
prop_test_a04$p.value
prop_test_a05$p.value
prop_test_a06$p.value

```

  * For sample A as we move away from 4% conversion rate the p-value gets smaller which indicates that the the the probability that the conversion rate is truly around 4% is very high.
  
```{r}
true_a <- prop_a
true_b <- prop_b

prop_test_prop_b <- prop.test(x = samp_b, n = n_b, p = prop_b)
prop_test_b03 <- prop.test(x = samp_b, n = n_b, p = .03)
prop_test_b04 <- prop.test(x = samp_b, n = n_b, p = .04)
prop_test_b05 <- prop.test(x = samp_b, n = n_b, p = .05)
prop_test_b06 <- prop.test(x = samp_b, n = n_b, p = .06)
prop_test_b08 <- prop.test(x = samp_b, n = n_b, p = .08)
prop_test_b09 <- prop.test(x = samp_b, n = n_b, p = .09)
prop_test_b10 <- prop.test(x = samp_b, n = n_b, p = .10)
prop_test_b11 <- prop.test(x = samp_b, n = n_b, p = .11)

prop_test_prop_b$p.value
prop_test_b03$p.value
prop_test_b04$p.value
prop_test_b05$p.value
prop_test_b06$p.value
prop_test_b08$p.value
prop_test_b09$p.value
prop_test_b10$p.value
prop_test_b11$p.value
```

* For sample B as we move away from 10% conversion rate the p-value gets smaller which indicates that the the the probability that the conversion rate is truly around 10% is very high.