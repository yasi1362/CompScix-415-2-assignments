---
title: "COMPSCIX 415.2 Homework 9/Final"
author: "Yasmin Makoui"
date: "8/7/2018"
output:
  html_document: 
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load_packages, warning=FALSE, message=FALSE}
library(tidyverse)
library(mdsr)
library(broom)
library(ggmap)
library(forecast)
library(tseries)
library(RgoogleMaps)
library(leaflet)
library(rgdal)
```

##Exercise 1 - Sampling Distributions, Functions and For Loops (10 points)

```{r}
# sample size
samp_size <- 100
# set the rate parameter
samp_rate <- 1/10000

# take sample
rexp(n = samp_size, rate = samp_rate)
```

###STEP 1

####Write an R function that does the following:

####Takes a sample of size samp_size from this exponential distribution (samp_size is an input parameter for the function)
####Calculates the mean of that sample
####Calculates the standard deviation of that sample
####Returns the calculated mean and standard deviation as a list 

```{r}

```

##Exercise 2 - Linear Regression (5 points)
####For this exercise we will return to the House Prices prediction dataset that we used for HW 7. You should have already downloaded the train.csv dataset before, but if you didn’t you can download it from Canvas in this week’s module.

####Load the train.csv dataset into R and fit a regression model with:
####y = SalePrice
####Features: LotArea, OverallQual, and ExterQual
####Answer these questions:
####Use the broom package to output the coefficients and the R-squared
```{r}
library(broom)
#import csv file
file_path_train <- '/Users/yasminmakoui/downloads/train.csv'
train_data <- read_csv(file = file_path_train)

# Fit a model with intercept only
mod <- lm(SalePrice ~ LotArea + OverallQual + ExterQual, data = train_data)

tidy(mod)

```

```{r}
library(broom)
# Fit a model with intercept only
mod_LA <- lm(SalePrice ~ LotArea, data = train_data)

tidy(mod_LA)
```

```{r}
library(broom)
# Fit a model with intercept only
mod_OQ <- lm(SalePrice ~ OverallQual, data = train_data)

tidy(mod_OQ)
```

```{r}
library(broom)
# Fit a model with intercept only
mod_EQ <- lm(SalePrice ~ ExterQual, data = train_data)

tidy(mod_EQ)
```

####Interpret the coefficient on LotArea: 
  * For every extra square foot in lot area, the sale price increases, on average, by $1.45, with all other features being held constant. 
```{r}
glance(mod_LA)
```

  * LotArea is statistically and practically significant.

####Interpret the coefficient on ExterQualGd
  * Excellent is our reference category for ExterQual
  * The mean difference in the sale price between Good and Excellent material on the exterior quality is -71,529 dollars, so good is less expensive by over 71K, with all other features being held constant. 

####Compare this model to the model we fit in HW 7 with GrLivArea,  OverallQual, Neighborhood. Which is the better fitting model?
```{r}
glance(mod)
```
  * Based on the adjusted R-squared (.69), the model seems to be a good fit to the data. However, the adjusted R-Squared in HW7 with GrLivArea,  OverallQual, Neighborhood is higher at (.78), which indicates the HW7 model is a better fitting model.
  
###Exercise 3 - AB Testing (5 points)
####Download the ab_test_data.csv file from Canvas. This file contains two columns: version and conversion. Each row is a visitor to a webpage. The  version column tells us which version of the webpage the visitor saw, and the  conversion column is a binary value and equals 1 if the visitor converted (0 otherwise).

####We want to perform an AB test on this data to see if the conversion rates are different for the two versions of the webpage.

####Answer these questions:

####a. What proportion of visitors converted for each version of the webpage?
```{r}
#import csv file
file_path_ab_data <- '/Users/yasminmakoui/downloads/ab_test_data.csv'
ab_data <- read_csv(file = file_path_ab_data)

ab_data_tibble <- as_tibble(ab_data)

ab_table_total <- ab_data_tibble %>% group_by(version, conversion) %>%
  summarize(conv_count = count(version))

ab_table_total
n_a <- (83+1917)
n_b <- (200+1800)

conv_a <- 83
conv_b <- 200

n_a
n_b

prop_a <- (conv_a/(n_a))
prop_b <- (conv_b/(n_b))

prop_a
prop_b
```
  * Version A coversion rate is 4.15%
  * Version B conversion rate is 10%

####b. Perform the AB test in R. What is the p-value for the AB test (hypothesis test of proportions)?
```{r}
true_a <- prop_a
true_b <- prop_b

samp_a <- rbinom(n = 1, size = n_a, prob = true_a)
samp_b <- rbinom(n = 1, size = n_b, prob = true_b)

samp_a
samp_b
```

```{r}
m <- 1000
samp_a <- rbinom(n = m, size = n_a, prob = true_a)
samp_b <- rbinom(n = m, size = n_b, prob = true_b)

plot_ab <- as_tibble(list(samp_a = samp_a/n_a, samp_b = samp_b/n_b))
plot_ab %>% ggplot(aes(x = samp_a)) +
  geom_histogram(binwidth = .001) +
  xlab('Sample proportions for Version A') +
  theme_bw()


```

```{r}
plot_ab %>% ggplot(aes(x = samp_b)) +
  geom_histogram(binwidth = .001) +
  xlab('Sample proportions for Version B') +
  theme_bw()
```

```{r}
true_a <- prop_a
true_b <- prop_b

samp_a <- rbinom(n = 1, size = n_a, prob = true_a)
samp_b <- rbinom(n = 1, size = n_b, prob = true_b)

two_prop_test <- prop.test(c(samp_a, samp_b), c(1000, 1000))
two_prop_test$p.value
```

  * The P-Value is small, so the conversion rates for Version A and B are significantly different than each other, so we'd conclude here that whatever changes were made to the webpage had an effect.
